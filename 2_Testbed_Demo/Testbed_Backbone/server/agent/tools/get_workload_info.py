from __future__ import annotations

## When running alone, you need to add
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))))

import re
import warnings
from typing import Dict

from langchain.prompts import PromptTemplate
# from server.agent import model_container
import json

# from langchain.chains import LLMChain
import random

from pydantic import BaseModel, Field

_PROMPT_TEMPLATE = """
To assess this question, you need to generate a corresponding SQL statement. Then, execute the SQL statement and return the corresponding result in the database.

Note that you must ensure that the generated SQL statements comply with the syntax and database structure. If you are not clear about the database structure, please call 'database_structure_info_tool' first.

Your response should follow the format below. Please note that all marks like ```text must be included, as they are used to extract the answers.

```text
${{SQL you generated to execute}}


```output (not generated by you)
${{Specific information returned by the tool}}


```answer
${{Your answer}}


Now, My question is:
question: {question}
"""

PROMPT = PromptTemplate(
    input_variables=["question"],
    template=_PROMPT_TEMPLATE,
)

def get_workload_info(query):
    try:
        # Read the workload1.json file
        with open("./configs/workload1.json", 'r') as f:
            workload_info = json.load(f)

        # Attach a random frequency between 1 and 1000 to each string
        for i in range(len(workload_info)):
            workload_info[i] = {
                "query": workload_info[i],
                "frequency": random.randint(1, 1000)
            }

        return str(workload_info[:10])
    except Exception as e:
        return str(e) + " Failed to obtain workload. Please check whether the workload1.json file exists."

def database_workload_info(query: str):
    # model = model_container.MODEL
    # llm_weather = LLMChain.from_llm(model, verbose=True, prompt=PROMPT)
    res = get_workload_info(query)
    ans = {"text": res}
    return ans

class DBWorkloadInput(BaseModel):
    query: str = Field(description="Only need input \"None\". ")


if __name__ == "__main__":
    print(database_workload_info(""))